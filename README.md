# MSMM
The code and data samples of the paper "A Multi-Scale Matching Method for High Quality UAV-Based Geo- Localization"

The task of object localization from UAV (Unmanned Aerial Vehicle) view is a new research area of image processing. The aim of this project is to accurately match images captured by UAVs with other images from different devices to determine their locations based on data. This technology can be used for UAV precision express (such as handing out masks without in-person contact during a pandemic) and agriculture big data statistics (such as estimating crop yields in a given area through satellite images). The main aim of this research project is to realize the object localization from UAV view. When given images or videos from UAV view, the identification system can match these with similar satellite images, use GPS data such as latitude and longitude to locate the object, and verify the localization results. We constructed a real-world multi-source dataset called UAV-166 for UAV-based geo-localization. Due to the high cost of annotating a large quantity of actual data, this project adopts the weakly supervised object localization to match satellite images with UAV view images under the condition that the accurate coordinates of the target building cannot be obtained. Furthermore, we proposed a multi-scale matching method (MSMM) to match satellite images and UAV perspectives at different levels to achieve higher accuracy. The system can achieve the RANK @ 1 accuracy of 69.52% and AP accuracy of 74.43%.]

UAV-166 Dataset Example: https://drive.google.com/file/d/1xoLeQDWwpCBNsUxbx4jcZ9wzFflJCssm/view?usp=sharing

<img width="447" alt="image" src="https://user-images.githubusercontent.com/94770292/173477654-eb974790-5dcf-4097-81ad-cb33f4aee6dd.png">
